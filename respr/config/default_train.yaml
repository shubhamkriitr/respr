description: "This is a sample config to run the pipeline"

pipeline:
  name: "TrainingPipeline"
instructions: {}

trainer: # currently using trainer from pytorch lightning 
  name: null
  args: []
  kwargs:
    max_epochs: 50
    # not use `check_val_every_n_epoch` if using `val_check_interval`
    # check_val_every_n_epoch: 1
    val_check_interval: 0.25 
    # fast_dev_run: true # for debugging only
    # limit_train_batches: 0.01 # for debugging only
    # overfit_batches=0.01 # for debugging only
    enable_progress_bar: true
    # resume_from_checkpoint: null
    # <<< FOR GPU >>>
    # accelerator: gpu
    # devices: 1


model:
  name: "LitResprResnet18"
  args: []
  kwargs: {}
dataloading:
  name: "ResprDataLoaderComposer"
  args: []
  kwargs:
    config:
      dataset: "BaseResprCsvDataset"
      dataset_path: "../../artifacts/frozen/dataset_capnobase_w32_s1_artif_cleaned_commit_c4dec47.csv"
      batch_size: 16
      num_workers: 0
      augmentation: null # to be added later #TODO
      num_folds: 5
      val_split: 0.1
      test_split: 0.1
    # MINI DATASET FOR DEV
    # config:
    #   dataset: "BaseResprCsvDataset"
    #   dataset_path: "../../artifacts/frozen/mini/dataset_capnobase_w32_s1_4_subjects.csv"
    #   batch_size: 16
    #   augmentation: null # to be added later #TODO
    #   num_folds: 2
    #   val_split: 0.25
    #   test_split: 0.25


# data_adapter:
#   name: "CapnobaseMatDataAdapter"
#   args: []
#   kwargs:
#     config:
#       data_root_dir: "../../Datasets/bidmc-ppg-and-respiration-dataset-1.0.0/bidmc_csv"
