description: "Leave one out CV
  same as exp 12, but monitor val_rmse
  same as exp 12g + @changes: 
    * monitor val_mae
    * use contrastive loss training (code@ commit 7405b61b516d22)
  same as exp 22 + @changes:
    * start from pretrained weights (from exp 23)
  "
output_dir: "../../artifacts/exp_24_SimCLR_cnn_on_mean_gt_old_csv_w32_stride4_LOOCV"
pipeline:
  name: "TrainingPipelineSimCLR"
instructions:
  do_only_test: false # make sure to set `ckpt_path`

training_init_model_ckpt_path: "../../artifacts/TODO" # loads weights from here before training

trainer: # currently using trainer from pytorch lightning 
  name: null
  args: []
  kwargs:
    max_epochs: 15
    # not use `check_val_every_n_epoch` if using `val_check_interval`
    # check_val_every_n_epoch: 1
    val_check_interval: 1.0 
    # fast_dev_run: true # for debugging only
    # limit_train_batches: 0.01 # for debugging only
    # overfit_batches=0.01 # for debugging only
    enable_progress_bar: true
    # overfit_batches: 5 #batches
    # resume_from_checkpoint: null
    # <<< FOR GPU >>>
    accelerator: gpu
    devices: [0]

callbacks: [
  {type: model_checkpoint, 
  monitor: train_contrastive_loss,
  save_top_k: 4,
  ckpt_filename: null}
]


model_checkpoint:
  monitor: val_rmse
  save_top_k: 4
  ckpt_filename: null

model: # model => actual model + lighting wrapper
  name: "LitResprMCDropoutCNNSimCLR"
  args: []
  kwargs:
    config:
      optimization:
        lr: 1.0e-3
        weight_decay: 1.0e-4
      num_monte_carlo_rollouts: 10
      model_module_class: ResprMCDropoutCNNResnet18SimCLR
      module_config: # config for the actual pytorch model
      # it will be passed as config kwarg like so `model_module(config=...)`
        input_channels: 1
        force_reshape_input: false
      y_normalization: # added in new #TODO: use this entry
        y_mean: 18.8806 # from CAPNOBASE (as was used for older experiments)
        y_std: 9.8441 # from CAPNOBASE (as was used for older experiments)
      mode_schedule: [[[0, 90], "regression"]]
      batch_size: 16 # MUST match training batch size
      model_save_step: 1 # NOT USED

dataloading:
  name: "ResprCsvDataLoaderComposer"
  args: []
  kwargs:
    # config:
      # dataset: "BaseResprCsvDataset"
      # dataset_path: "../../artifacts/frozen/dataset_capnobase_w32_s1_artif_cleaned_commit_c4dec47.csv"
      # batch_size: 16
      # num_workers: 0
      # augmentation: null # to be added later #TODO
      # num_folds: 5
      # start_fold: 0
      # val_split: 0.2
      # test_split: 0.2
      # ckpt_path: ../../artifacts/2022-11-17_050120/fold_00/lightning_logs/version_2482287/checkpoints/epoch=7-step=6717.ckpt
    # MINI DATASET FOR DEV
    config:
      dataset: 
        name: "DatasetAndAugmentationWrapper"
        args: []
        kwargs:
          config:
            underlying_dataset:
              name: "BaseResprCsvDataset"
              args: []
              kwargs:
                config: {}
            data_augmentation:
              name: "BaseResprDataAugmentationComposerSimCLR"
              args: []
              kwargs:
                config: {}
      val_dataset: "BaseResprCsvDatasetDuplicateX"
      test_dataset: "BaseResprCsvDatasetDuplicateX"
      dataset_path: "../../artifacts/frozen/dataset_capnobase_w32_s4_artif_cleaned_gt_mean_commit-f69eea50.csv"
      batch_size: 16
      augmentation: null # to be added later #TODO
      num_folds: 42
      start_fold: 0
      val_split: 0.2
      test_split: 0.023 # ~1/42
      num_workers: 0



# data_adapter:
#   name: "CapnobaseMatDataAdapter"
#   args: []
#   kwargs:
#     config:
#       data_root_dir: "../../Datasets/bidmc-ppg-and-respiration-dataset-1.0.0/bidmc_csv"


# dataset_capnobase_w32_s16_artif_cleaned_gt_mean_commit_cbcf0ac2b00.csv
# dataset_capnobase_w32_s16_artif_cleaned_gt_mid_commit_71f269d1a7.csv
# dataset_capnobase_w32_s1_artif_cleaned_commit_c4dec47.csv
# dataset_capnobase_w32_s1_artif_cleaned_gt_mid_commit_1995ef9cc.csv
# dataset_capnobase_w32_s32_artif_cleaned_gt_mean_commit_176d24c06a.csv
# dataset_capnobase_w32_s32_artif_cleaned_gt_mid_commit_4f6bc5f69fb.csv
# dataset_capnobase_w32_s4_artif_cleaned_gt_mean_commit-f69eea50.csv
# dataset_capnobase_w32_s4_artif_cleaned_gt_mid_commit_63b398dd.csv
# dataset_capnobase_w32_s8_artif_cleaned_gt_mean_commit_0ff4049a.csv
# dataset_capnobase_w32_s8_artif_cleaned_gt_mid_commit_cba0919a699.csv